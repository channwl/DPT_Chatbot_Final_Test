import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import List, Dict, Tuple
import time
import sys
import os
from langchain_openai import OpenAIEmbeddings

# Django ì„¤ì •
sys.path.append('/Users/gimchan-ul/Desktop/ê²¨ìš¸ í”„ë¡œì íŠ¸/DPT-chatbot-main')
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'dpt_project.settings')
import django
django.setup()

from chatbot.utils import RAGSystem
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from dpt_project import settings

class RAGExperiment:
    def __init__(self):
        self.test_questions = self.load_test_questions()
        self.results = []
        
    def load_test_questions(self) -> List[Dict]:
        """í…ŒìŠ¤íŠ¸ ì§ˆë¬¸ ë¡œë“œ"""
        df = pd.read_excel('chatbot/ìµœì¢…_Testset.xlsx')
        # ì§ˆë¬¸ ID 1-20ë§Œ ì‚¬ìš© (ì‹¤í—˜ìš©, API ë¹„ìš© ê³ ë ¤)
        test_df = df[(df['ì§ˆë¬¸ ID'] >= 1) & (df['ì§ˆë¬¸ ID'] <= 20)]
        
        questions = []
        for _, row in test_df.iterrows():
            questions.append({
                'id': row['ì§ˆë¬¸ ID'],
                'question': row['ì§ˆë¬¸'],
                'reference': row['ì •ë‹µ']
            })
        return questions
    
    def generate_faiss_index_with_chunk_size(self, chunk_size: int):
        """íŠ¹ì • chunk sizeë¡œ FAISS ì¸ë±ìŠ¤ ìƒì„±"""
        pdf_dir = "chatbot/data/"
        all_documents = []
        
        pdf_files = [file for file in os.listdir(pdf_dir) if file.endswith(".pdf")]
        
        for file_name in pdf_files:
            from langchain_community.document_loaders import PyMuPDFLoader
            loader = PyMuPDFLoader(os.path.join(pdf_dir, file_name))
            documents = loader.load()
            for d in documents:
                d.metadata['file_path'] = os.path.join(pdf_dir, file_name)
            all_documents.extend(documents)
        
        # ìƒˆë¡œìš´ chunk sizeë¡œ ë¬¸ì„œ ë¶„í• 
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size, 
            chunk_overlap=chunk_size // 8  # chunk_sizeì˜ 1/8ë¡œ overlap ì„¤ì •
        )
        chunks = splitter.split_documents(all_documents)
        
        # FAISS ì¸ë±ìŠ¤ ìƒì„±
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key='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'
        )
        vector_store = FAISS.from_documents(chunks, embeddings)
        vector_store.save_local(f"faiss_index_chunk_{chunk_size}")
        print(f"âœ… Chunk size {chunk_size}ë¡œ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ!")
        
    def evaluate_retrieval_accuracy(self, chunk_size: int, k: int) -> float:
        """íŠ¹ì • chunk_sizeì™€ k ê°’ìœ¼ë¡œ ê²€ìƒ‰ ì •í™•ë„ í‰ê°€ (LLM-as-a-Judge ë°©ì‹, Memory í¬í•¨)"""
        
        # RAGSystem ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (Memory í¬í•¨)
        rag_system = RAGSystem(llm_type="openai")
        
        # í•´ë‹¹ chunk_sizeì˜ ì¸ë±ìŠ¤ë¡œ êµì²´
        embeddings = OpenAIEmbeddings(
            model="text-embedding-3-small",
            openai_api_key=''
        )
        vector_store = FAISS.load_local(
            f"faiss_index_chunk_{chunk_size}", 
            embeddings, 
            allow_dangerous_deserialization=True
        )
        
        # RAGSystemì˜ vector_dbë¥¼ êµì²´
        rag_system._vector_db = vector_store
        rag_system._retriever = vector_store.as_retriever(search_kwargs={"k": k})
        
        # LLM-as-a-Judgeë¥¼ ìœ„í•œ OpenAI í´ë¼ì´ì–¸íŠ¸
        from openai import OpenAI
        client = OpenAI(api_key='')
        
        total_score = 0
        valid_questions = 0
        
        for question_data in self.test_questions:
            try:
                # RAGSystemìœ¼ë¡œ ë‹µë³€ ìƒì„± (Memory í¬í•¨)
                answer = rag_system.process_question(question_data['question'])
                
                # LLM-as-a-Judge í‰ê°€ í”„ë¡¬í”„íŠ¸ (Memory í¬í•¨ëœ ë‹µë³€ í‰ê°€)
                judge_prompt = f"""
ë‹¹ì‹ ì€ AI ëª¨ë¸ì˜ ì‘ë‹µì„ ê²€í† í•˜ê³  ì •í™•ì„±ì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¹ì‹ ì˜ ëª©í‘œëŠ” ê¸°ì¤€ ì •ë‹µê³¼ ë¹„êµí•˜ì—¬ AI ì‘ë‹µì´ ì‚¬ì‹¤ì„ ì–¼ë§ˆë‚˜ ì •í™•íˆ ë°˜ì˜í–ˆëŠ”ì§€ë¥¼ íŒë‹¨í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ë‹¤ìŒì€ ì‚¬ìš©ì ì§ˆë¬¸, ê¸°ì¤€ ì •ë‹µ, ê·¸ë¦¬ê³  AI ëª¨ë¸ì˜ ì‘ë‹µì…ë‹ˆë‹¤.

ì•„ë˜ ì‘ë‹µì˜ ì •í™•ì„±ì„ ê¸°ì¤€ ì •ë‹µê³¼ ë¹„êµí•˜ì—¬ ë‹¨ê³„ì ìœ¼ë¡œ ìƒê°í•˜ê³ , ê·¸ ê³¼ì •ì€ ë‚´ë¶€ì ìœ¼ë¡œë§Œ ìˆ˜í–‰í•˜ì„¸ìš”.
ì¶œë ¥ì€ ì˜¤ì§ 1~5 ì‚¬ì´ì˜ ìˆ«ì ì¤‘ í•˜ë‚˜ë§Œ í¬í•¨í•´ì•¼ í•˜ë©°, ì„¤ëª…ì€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

### ì‚¬ìš©ì ì§ˆë¬¸:
{question_data['question']}

### ê¸°ì¤€ ì •ë‹µ:
{question_data['reference']}

### AI ì‘ë‹µ (Memory í¬í•¨):
{answer}

[ì •í™•ì„± í‰ê°€ ê¸°ì¤€]
- 5ì : ê¸°ì¤€ ì •ë‹µì˜ ì‚¬ì‹¤ì„ ì™„ë²½íˆ í¬í•¨í•˜ê³  ìˆê³ , ì˜¤ë¥˜ ì—†ì´ ì •í™•í•¨.
- 4ì : ê±°ì˜ ëª¨ë“  ì‚¬ì‹¤ì„ í¬í•¨í•˜ë‚˜, ì‚¬ì†Œí•œ ëˆ„ë½ì´ë‚˜ í‘œí˜„ìƒì˜ ë¶€ì •í™•ì„±ì´ ìˆìŒ.
- 3ì : ì£¼ìš” ì •ë³´ëŠ” í¬í•¨í•˜ë‚˜ ì¼ë¶€ ì˜¤ë¥˜ë‚˜ ëˆ„ë½ì´ ìˆìŒ.
- 2ì : ì¤‘ìš”í•œ ì •ë³´ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ëª…ë°±í•œ ì˜¤ë¥˜ê°€ í¬í•¨ë¨.
- 1ì : ì˜ëª»ëœ ì •ë³´ ë˜ëŠ” ì „í˜€ ë§ì§€ ì•ŠëŠ” ì‚¬ì‹¤ í¬í•¨.

ì´ì œ ì§ˆë¬¸ì„ ë³´ê³  ìƒê° ê³¼ì •ì„ ê±°ì¹œ ë’¤, ë§ˆì§€ë§‰ ì¤„ì— 1~5 ì¤‘ í•˜ë‚˜ì˜ ìˆ«ìë§Œ ì‘ì„±í•˜ì„¸ìš”.
"""
                
                # LLM í‰ê°€ ìš”ì²­
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ AI í‰ê°€ìì…ë‹ˆë‹¤."},
                        {"role": "user", "content": judge_prompt}
                    ],
                    temperature=0
                )
                
                score_text = response.choices[0].message.content.strip()
                
                # ìˆ«ì ì¶”ì¶œ (1-5 ë²”ìœ„)
                try:
                    score = float(score_text)
                    if 1 <= score <= 5:
                        total_score += score
                        valid_questions += 1
                        print(f"âœ… {question_data['id']}ë²ˆ ì™„ë£Œ - ì ìˆ˜: {score}")
                    else:
                        print(f"ì˜¤ë¥˜ ë°œìƒ (ì§ˆë¬¸ ID {question_data['id']}): ì ìˆ˜ ë²”ìœ„ ì˜¤ë¥˜ ({score})")
                except ValueError:
                    print(f"ì˜¤ë¥˜ ë°œìƒ (ì§ˆë¬¸ ID {question_data['id']}): ì ìˆ˜ íŒŒì‹± ì˜¤ë¥˜ ({score_text})")
                
                time.sleep(1.5)  # API ì†ë„ ì œí•œ ë°©ì§€
                
            except Exception as e:
                print(f"ì§ˆë¬¸ {question_data['id']} í‰ê°€ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        return total_score / valid_questions if valid_questions > 0 else 0
    
    def run_experiment(self):
        """ì „ì²´ ì‹¤í—˜ ì‹¤í–‰"""
        chunk_sizes = [100,300,500,700]
        k_values = [1, 3, 5, 7]
        
        print("ğŸš€ RAG íŒŒë¼ë¯¸í„° ì‹¤í—˜ ì‹œì‘!")
        
        for chunk_size in chunk_sizes:
            print(f"\nğŸ“Š Chunk size {chunk_size} ì‹¤í—˜ ì¤‘...")
            
            # í•´ë‹¹ chunk_sizeë¡œ ì¸ë±ìŠ¤ ìƒì„±
            self.generate_faiss_index_with_chunk_size(chunk_size)
            
            for k in k_values:
                print(f"  - k={k} í‰ê°€ ì¤‘...")
                accuracy = self.evaluate_retrieval_accuracy(chunk_size, k)
                
                self.results.append({
                    'chunk_size': chunk_size,
                    'k': k,
                    'accuracy': accuracy
                })
                
                print(f"    ê²°ê³¼: {accuracy:.4f}")
        
        # ê²°ê³¼ ì €ì¥
        results_df = pd.DataFrame(self.results)
        results_df.to_excel('rag_experiment_results.xlsx', index=False)
        print(f"\nâœ… ì‹¤í—˜ ì™„ë£Œ! ê²°ê³¼ê°€ 'rag_experiment_results.xlsx'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return results_df
    
    def plot_results(self, results_df: pd.DataFrame):
        """ê²°ê³¼ ì‹œê°í™”"""
        plt.figure(figsize=(12, 8))
        
        # k ê°’ë³„ë¡œ ë‹¤ë¥¸ ì„  ìŠ¤íƒ€ì¼
        line_styles = ['-', '--', '-.', ':']
        colors = ['blue', 'red', 'green', 'orange']
        
        for i, k in enumerate([1, 3, 5, 7]):
            k_data = results_df[results_df['k'] == k]
            plt.plot(
                k_data['chunk_size'], 
                k_data['accuracy'], 
                marker='o', 
                linestyle=line_styles[i],
                color=colors[i],
                linewidth=2,
                markersize=8,
                label=f'k={k}'
            )
        
        plt.xlabel('Chunk Size', fontsize=14)
        plt.ylabel('ê²€ìƒ‰ ì •í™•ë„', fontsize=14)
        plt.title('RAG ì‹œìŠ¤í…œ: Chunk Sizeì™€ k ê°’ì— ë”°ë¥¸ ê²€ìƒ‰ ì •í™•ë„', fontsize=16)
        plt.legend(fontsize=12)
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        
        # ê·¸ë˜í”„ ì €ì¥
        plt.savefig('rag_experiment_results.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        print("ğŸ“ˆ ê·¸ë˜í”„ê°€ 'rag_experiment_results.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    experiment = RAGExperiment()
    
    # ì‹¤í—˜ ì‹¤í–‰
    results = experiment.run_experiment()
    
    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“‹ ì‹¤í—˜ ê²°ê³¼ ìš”ì•½:")
    print(results.pivot_table(index='chunk_size', columns='k', values='accuracy'))
    
    # ê·¸ë˜í”„ ìƒì„±
    experiment.plot_results(results)

if __name__ == "__main__":
    main() 
